# Configuring the OpenTelemetry Demo App to send data to Oracle Cloud Infrastucture (OCI) backend

The [OpenTelemetry Astronomy Shop](https://github.com/open-telemetry/opentelemetry-demo) is a demo app to illustrate the implementation of OpenTelemetry in a near real-world environment. It is a microservice-based distributed system which can be easily deployed using Docker or Kubernetes, where we will focus here on deploying it using Kubernetes/Helm.

Our aim is to guide you through the needed steps to deploy the OpenTelemetry Demo in a K8s cluster and send its data to OCI Observability and Management Services.

## Prerequisites
The following prerequisites are needed:
1. Ensure to have an [OCI account](https://signup.cloud.oracle.com).
2. In Application Performance Monitoring (APM) service, [create an APM domain.](https://docs.oracle.com/iaas/application-performance-monitoring/doc/create-apm-domain.html)
3. Have the [Data Upload Endpoint URL and the private data key](https://docs.oracle.com/en-us/iaas/application-performance-monitoring/doc/obtain-data-upload-endpoint-and-data-keys.html#GUID-912EA36F-4E58-4954-B9C2-4E9A9BADDAE9) of that domain available.
4. Have a Kubernetes Cluster available, either locally, in OCI or at other cloud vendors.

## Deploy the Demo App
We will start by creating a dedicated namespace for the demo app:
```bash
kubectl create namespace otel-demo-app
```
Next, we will create a secret named <samp>oci-apm-secret</samp>:
```bash
kubectl create secret generic oci-apm-secret -n otel-demo-app --from-literal="OCI_APM_ENDPOINT=<Data Upload Endpoint>" --from-literal="OCI_APM_DATAKEY=<Data Key>"
```
Add the OpenTelemetry Helm charts site to your repo to allow deploying the OpenTelemetry Demo:
```bash
helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts
```
Create file <samp>my-values.yaml</samp> with the following content:
```
opentelemetry-collector:
  extraEnvsFrom:
    - secretRef:
        name: oci-apm-secret

  config:
    exporters:
      otlphttp/oci_spans:
        endpoint: "${OCI_APM_ENDPOINT}/20200101/opentelemetry/"
        headers:
          authorization: "dataKey ${OCI_APM_DATAKEY}"
        tls:
          insecure: false
      otlphttp/oci_metrics:
        endpoint: "${OCI_APM_ENDPOINT}/20200101/observations/metric?dataFormat=otlp-metric&dataFormatVersion=1"
        headers:
          authorization: "dataKey ${OCI_APM_DATAKEY}"
        tls:
          insecure: false

    service:
      pipelines:
        traces:
          exporters: [otlp, debug, spanmetrics, otlphttp/oci_spans]
        metrics:
          exporters: [otlphttp/prometheus, debug, otlphttp/oci_metrics]
```
Run the following <samp>helm</samp> command to deploy the OpenTelemetry Demo App:
```bash
helm install otel-demo-app open-telemetry/opentelemetry-demo --values my-values.yaml -n otel-demo-app
```
Here is the expected output:
```bash
...

 ██████╗ ████████╗███████╗██╗         ██████╗ ███████╗███╗   ███╗ ██████╗
██╔═══██╗╚══██╔══╝██╔════╝██║         ██╔══██╗██╔════╝████╗ ████║██╔═══██╗
██║   ██║   ██║   █████╗  ██║         ██║  ██║█████╗  ██╔████╔██║██║   ██║
██║   ██║   ██║   ██╔══╝  ██║         ██║  ██║██╔══╝  ██║╚██╔╝██║██║   ██║
╚██████╔╝   ██║   ███████╗███████╗    ██████╔╝███████╗██║ ╚═╝ ██║╚██████╔╝
 ╚═════╝    ╚═╝   ╚══════╝╚══════╝    ╚═════╝ ╚══════╝╚═╝     ╚═╝ ╚═════╝


- All services are available via the Frontend proxy: http://localhost:8080
  by running these commands:
     kubectl --namespace default port-forward svc/otel-demo-app-frontendproxy 8080:8080

  The following services are available at these paths after the frontendproxy service is exposed with port forwarding:
  Webstore             http://localhost:8080/
  Jaeger UI            http://localhost:8080/jaeger/ui/
  Grafana              http://localhost:8080/grafana/
  Load Generator UI    http://localhost:8080/loadgen/
  Feature Flags UI     http://localhost:8080/feature/    
```

## Using OCI APM service to observe Traces and Spans
With the OpenTelemetry Demo App installed, you are now ready to explore the capabilities of OCI APM (Application Performance Monitoring) and gain deep insights into your application's performance. Lets start by showing you the process of visualising spans and traces using OCI APM, showcasing its powerful features and benefits.

### Getting Started with OCI APM
Log in to your Oracle Cloud Infrastructure console and navigate to the Application Performance Monitoring. Here, you will find a wealth of information about your application's performance

### Visualising Traces and Spans
Click on the "Traces" tab in the APM console / Trace Explorer. You will see a list of traces generated by the OTel demo application. Each trace represents a user request or an operation within your application:

![Trace-Explorer-05](https://github.com/user-attachments/assets/81e98ec3-cac9-4498-9c58-4a204e361dc0)

Select a specific trace to view its details, including the span topology and tree topology:

![Trace-Explorer-04](https://github.com/user-attachments/assets/e864abb7-3db0-4491-8bde-a3a7e7141c30)

Click on any of the spans to see the span details, which include kubernetes data, SpanId, TraceID, etc.:

![Trace-Explorer-03](https://github.com/user-attachments/assets/c6244f5c-c8ba-418b-a5dd-eac696e9cea9)

Services Topology view allows to visualize associations between services, several parameters can be used for the arrow width:

![Service-Topology-07](https://github.com/user-attachments/assets/78e97dde-f569-4e18-b9e2-ebc5c95077f5)

![Service-Topology-08](https://github.com/user-attachments/assets/be3f58ec-7875-4514-a759-36e8297e2488)

## Using OCI Logging Analytics service to collect and analyze Logs from Kubernetes Infrastructure and Pods
OCI Logging Analytics provides a [complete solution](https://docs.oracle.com/en-us/iaas/logging-analytics/doc/kubernetes-solution.html) for monitoring Kubernetes (K8s) cluster deployed in OCI, third party public clouds, private clouds, or on-premises including managed Kubernetes deployments. We will start with discovering the K8s cluster running the OpenTelemetry Demo App.

### Getting Started with monitoring a K8s Cluster using OCI Logging Analytics
Log in to your Oracle Cloud Infrastructure console and navigate to Logging Analytics Administration. Select Solutions -> Kubernetes -> Connect Clusters -> Monitor Kubernetes -> Oracle OKE, here we are assuming that the K8s cluster is running in OCI. Select the Cluster, press *Next* and select the right compartment to be used for telemetry data and related monitoring resources, usually it will be the same like the one used for collecting the logs. Click on *Configure log collection*, this will create all neded dynamic groups and policies to allow collecting logs, metrics, and object information from related Kubernetes components, computer nodes, subnets, and load balancers. The deployed solution will create these statefulsets, daemonsets and cronjobs in namespace *oci-onm*:
```bash
$ kubectl get pods -n oci-onm
NAME                               READY   STATUS      RESTARTS   AGE
oci-onm-discovery-28982290-zdkxx   0/1     Completed   0          14m
oci-onm-discovery-28982295-bztr2   0/1     Completed   0          9m12s
oci-onm-discovery-28982300-zrxxq   0/1     Completed   0          4m12s
oci-onm-logan-krcmb                1/1     Running     3          80d
oci-onm-logan-npltp                1/1     Running     2          80d
oci-onm-logan-tthvm                1/1     Running     2          80d
oci-onm-mgmt-agent-0               1/1     Running     2          80d
```
### Screenshots from the Solution Dashboard
Cluster overview:
![K8s-Solution-01](https://github.com/user-attachments/assets/3d767718-60aa-4b47-b84a-93fedf5f9db4)

Workload overview:
![K8s-Solution-02](https://github.com/user-attachments/assets/e8bad199-f6c0-4155-8140-0758cdffab12)

Node overview:
![K8s-Solution-03](https://github.com/user-attachments/assets/ce809518-70e9-4d09-8cbe-0f3ff4662172)

Pod overview:
![K8s-Solution-04](https://github.com/user-attachments/assets/a0d7dbe1-9cc9-4219-886e-fa8f4691a382)

### Screenshots from Log Explorer

List of TOP Log Sources:
![K8s-Log-Sources](https://github.com/user-attachments/assets/a4637601-d932-436a-9921-2f333f0d5450)

Log Records by Pod name:
![K8s-Log-by-Pods](https://github.com/user-attachments/assets/47934bca-3084-47e7-87e6-4df986cbe42a)

Compare Cluster results:
![K8s-Log-Sources_compare-cluster](https://github.com/user-attachments/assets/27d78650-85fe-4c73-9566-08e115e3ebc4)


## Using OCI Monitoring service to inspect the collected metrics

Metrics from the OpenTelemetry Demo App are routed via OpenTelemetry Collector to OCI APM service which in turn will forwarded them to OCI Monitoring service. In parallel, infrastructure metrics from the Kubernetes cluster itself are getting collected by the OCI Management Agent which is running as statefulset in the cluster.

The collected metrics can be inspected using the Metrics Explorer from the OCI Monitoring service.

Metrics collected by the Management Agent can be found in metric namespace *mgmtagent_kubernetes_metrics*:

![Metrics-Explorer-06](https://github.com/user-attachments/assets/9863f36e-7097-4b34-ae7e-c11454335118)


Metrics sent by the OpenTelemetry Collector can be found in metric namespace *oracle_apm_monitoring*:

![Metrics-Explorer-03](https://github.com/user-attachments/assets/1aa3bea0-4bd1-4bba-81e1-eff9a2d474ea)

Finally, out-of-the-box or custom dashboards can be used to visualize the collected metrics:

![k8s-metrics-dashboard-01](https://github.com/user-attachments/assets/5b93d412-4974-4049-a22b-5c8d5be89fc1) 

![k8s-metrics-dashboard-02](https://github.com/user-attachments/assets/8b6ff3d8-f168-4581-b68e-0baf21b5b986)


